{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:21:51.936483Z",
     "start_time": "2024-12-11T13:21:50.829408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mitja/anaconda3/envs/multimodal_decoding/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from utils import STIM_INFO_PATH, COCO_IMAGES_DIR, STIMULI_IDS_PATH, SUBJECTS, FMRI_DATA_DIR\n",
    "from eval import get_distance_matrix\n",
    "from data import get_fmri_data_paths, get_latent_features, LatentFeatsConfig, standardize_latents, IMAGE, CAPTION, SPLIT_TRAIN, SPLIT_TEST, SPLIT_IMAGERY\n",
    "from analyses.decoding.ridge_regression_decoding import get_run_str, RIDGE_DECODER_OUT_DIR, RESULTS_FILE\n",
    "from feature_extraction.feat_extraction_utils import CoCoDataset\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "from preprocessing.create_gray_matter_masks import get_graymatter_mask_path\n",
    "import nibabel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from io import BytesIO\n",
    "import base64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_ds = CoCoDataset(COCO_IMAGES_DIR, STIM_INFO_PATH, STIMULI_IDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(image, length=100):\n",
    "    if image.size[0] < image.size[1]:\n",
    "        resized_image = image.resize((length, int(image.size[1] * (length / image.size[0]))))\n",
    "        required_loss = (resized_image.size[1] - length)\n",
    "        resized_image = resized_image.crop(box=(0, required_loss / 2, length, resized_image.size[1] - required_loss / 2))\n",
    "    else:\n",
    "        resized_image = image.resize((int(image.size[0] * (length / image.size[1])), length))\n",
    "        required_loss = resized_image.size[0] - length\n",
    "        resized_image = resized_image.crop(box=(required_loss / 2, 0, resized_image.size[0] - required_loss / 2, length))\n",
    "    return resized_image\n",
    "\n",
    "def display_stimuli(coco_ids, imgs=True, caps=True):\n",
    "    if caps:\n",
    "        for coco_id in coco_ids:\n",
    "            print(coco_ds.captions[coco_id], end=\"\\n\")\n",
    "\n",
    "    if imgs:\n",
    "        imgs = [np.array(resize_img(coco_ds.get_img_by_coco_id(img_id))) for img_id in coco_ids]        \n",
    "        img = Image.fromarray(np.hstack(imgs))\n",
    "        display(img)\n",
    "\n",
    "def get_distance_matrix(predictions, originals, metric='cosine'):\n",
    "    dist = cdist(predictions, originals, metric=metric)\n",
    "    return dist\n",
    "    \n",
    "def dist_mat_to_pairwise_acc(dist_mat, stim_ids, print_details=False):\n",
    "    diag = dist_mat.diagonal().reshape(-1, 1)\n",
    "    comp_mat = diag < dist_mat\n",
    "    corrects = comp_mat.sum()\n",
    "    if print_details:\n",
    "        for i, stim_id in enumerate(stim_ids):\n",
    "            print(stim_id, end=': ')\n",
    "            print(f'{comp_mat[i].sum() / (len(comp_mat[i]) - 1):.2f}')\n",
    "    # subtract the number of elements of the diagonal as these values are always \"False\" (not smaller than themselves)\n",
    "    score = corrects / (dist_mat.size - diag.size)\n",
    "    return score\n",
    "\n",
    "def dist_mat_to_rankings(dist_mat, stim_ids, candidate_set_latent_ids):\n",
    "    all_ranks = []\n",
    "    for test_stimulus_id, nneighbors_row in zip(stim_ids, dist_mat):\n",
    "        nneighbors_ids = candidate_set_latent_ids[np.argsort(nneighbors_row)]\n",
    "        rank = np.argwhere(nneighbors_ids == test_stimulus_id)[0][0] + 1\n",
    "\n",
    "        all_ranks.append(rank)\n",
    "            \n",
    "    return np.mean(all_ranks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:22:18.708977Z",
     "start_time": "2024-12-11T13:22:14.335608Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load(betas_dir, model, subject, mode, feats_config):    \n",
    "    train_paths, stim_ids, stim_types = get_fmri_data_paths(betas_dir, subject, SPLIT_TRAIN, mode)    \n",
    "    train_latents = get_latent_features(feats_config, stim_ids, stim_types)\n",
    "    train_paths = np.array(train_paths)\n",
    "    \n",
    "    test_paths, test_stim_ids, test_stim_types = get_fmri_data_paths(betas_dir, subject, SPLIT_TEST)\n",
    "    test_latents = get_latent_features(feats_config, test_stim_ids, test_stim_types, test_mode=True)\n",
    "    test_paths = np.array(test_paths)\n",
    "    \n",
    "    train_latents, test_latents = standardize_latents(train_latents, test_latents)\n",
    "    \n",
    "    gray_matter_mask_data = nibabel.load(get_graymatter_mask_path(subject)).get_fdata()\n",
    "    gray_matter_mask = gray_matter_mask_data == 1\n",
    "    print(f\"Gray matter mask size: {gray_matter_mask.sum()}\")\n",
    "    \n",
    "    run_str = get_run_str(betas_dir, feats_config)\n",
    "    results_file_path = os.path.join(\n",
    "        RIDGE_DECODER_OUT_DIR, mode, subject, run_str, RESULTS_FILE\n",
    "    )\n",
    "    print(f'loading decoder results from: \\n', results_file_path)\n",
    "    results = pickle.load(open(results_file_path, 'rb'))\n",
    "    \n",
    "    return stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths\n",
    "\n",
    "def load_betas(train_paths, test_paths):\n",
    "    train_fmri_betas = []\n",
    "    for idx in trange(len(train_paths), desc=\"loading fmri data\"):\n",
    "        sample = nibabel.load(train_paths[idx]).get_fdata()\n",
    "        sample = sample[gray_matter_mask].astype('float32').reshape(-1)\n",
    "        train_fmri_betas.append(sample)\n",
    "    \n",
    "    train_fmri_betas = np.array(train_fmri_betas)\n",
    "\n",
    "    test_fmri_betas = []\n",
    "    for idx in trange(len(test_paths), desc=\"loading fmri data\"):\n",
    "        sample = nibabel.load(test_paths[idx]).get_fdata()\n",
    "        sample = sample[gray_matter_mask].astype('float32').reshape(-1)\n",
    "        test_fmri_betas.append(sample)\n",
    "    \n",
    "    test_fmri_betas = np.array(test_fmri_betas)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_fmri_betas)\n",
    "    train_fmri_betas_standardized = scaler.transform(train_fmri_betas)\n",
    "    test_fmri_betas_standardized = scaler.transform(test_fmri_betas)\n",
    "    \n",
    "    return train_fmri_betas, test_fmri_betas, train_fmri_betas_standardized, test_fmri_betas_standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features for imagebind: avg avg vision_features_cls lang_features_cls\n",
      "Gray matter mask size: 162649\n",
      "loading decoder results from: \n",
      " /home/mitja/data/multimodal_decoding/whole_brain_decoding/agnostic/sub-01/imagebind_avg_test_avg_vision_features_cls_lang_features_cls_betas/results.p\n"
     ]
    }
   ],
   "source": [
    "SUBJECT = 'sub-01'\n",
    "MODEL = \"imagebind\"\n",
    "\n",
    "# MODE = \"images\"\n",
    "MODE = \"agnostic\"\n",
    "\n",
    "BETAS_SUFFIX = 'betas'\n",
    "BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "# feats = 'avg'\n",
    "# test_feats = 'avg'\n",
    "FEATS = 'default'\n",
    "TEST_FEATS = 'default'\n",
    "# feats = 'lang'\n",
    "# test_feats = 'lang'\n",
    "# vision_feats = 'vision_features_cls'\n",
    "VISION_FEATS = 'default'\n",
    "# vision_feats = 'n_a'\n",
    "\n",
    "LANG_FEATS = 'default'\n",
    "# lang_feats = 'lang_features_cls'\n",
    "# lang_feats = 'lang_features_mean'\n",
    "\n",
    "FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths = load(BETAS_DIR, MODEL, SUBJECT, MODE, FEATS_CONFIG)\n",
    "\n",
    "N_TRAIN_BETAS = 1000\n",
    "train_paths = train_paths[np.random.choice(range(len(train_paths)), size=N_TRAIN_BETAS, replace=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading fmri data: 100%|██████████| 1000/1000 [00:35<00:00, 28.08it/s]\n",
      "loading fmri data: 100%|██████████| 140/140 [00:03<00:00, 38.08it/s]\n"
     ]
    }
   ],
   "source": [
    "train_fmri_betas, test_fmri_betas, train_fmri_betas_standardized, test_fmri_betas_standardized = load_betas(train_paths, test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_betas(train_betas, test_betas, title, binwidth=3):\n",
    "#     X = np.concatenate((train_betas.flatten(), test_betas.flatten()))\n",
    "#     hue = ['train'] * train_betas.size + ['test'] * test_betas.size\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     sns.histplot(x=X, hue=hue, binwidth=binwidth)\n",
    "#     plt.title(title)\n",
    "\n",
    "# print(np.nanmean(train_fmri_betas.mean(axis=0)))\n",
    "# print(np.nanmean(test_fmri_betas.mean(axis=0)))\n",
    "# print(np.nanmean(train_fmri_betas_standardized.mean(axis=0)))\n",
    "# print(np.nanmean(test_fmri_betas_standardized.mean(axis=0)))\n",
    "\n",
    "# plot_betas(train_fmri_betas, test_fmri_betas, title='unstandardized')\n",
    "# plt.ylim(0, 10000000)\n",
    "# plt.xlim(-25, 25)\n",
    "\n",
    "# plot_betas(train_fmri_betas_standardized, test_fmri_betas, title='standardized', binwidth=0.3)\n",
    "# plt.ylim(0, 4000000)\n",
    "# plt.xlim(-3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE for Betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_betas_tfce(train_betas, test_betas, title, train_subset=None):\n",
    "    if train_subset is not None:\n",
    "        train_betas_subset = train_betas[np.random.choice(range(len(train_betas)), size=train_subset, replace=False)]\n",
    "    else:\n",
    "        train_betas_subset = train_betas\n",
    "    train_test = np.concatenate((train_betas_subset, test_betas))\n",
    "    tsne = TSNE(n_components=2, learning_rate='auto', verbose=1, n_jobs=10, n_iter=1000)\n",
    "    X_embedded = tsne.fit_transform(train_test)\n",
    "    \n",
    "    print(X_embedded.shape)\n",
    "    assert X_embedded.shape[1] == 2\n",
    "    hue = ['train'] * len(train_betas_subset) + ['test'] * len(test_betas)\n",
    "    # alpha = [1] * len(test_betas) + [0.3] * len(train_betas_subset)\n",
    "    \n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.scatterplot(\n",
    "        x = X_embedded[:, 0], y = X_embedded[:, 1],\n",
    "        hue = hue,\n",
    "        # alpha = alpha\n",
    "    )\n",
    "    plt.title(title)\n",
    "\n",
    "plot_betas_tfce(train_fmri_betas, test_fmri_betas, title=\"not standardized\")\n",
    "plot_betas_tfce(train_fmri_betas_standardized, test_fmri_betas_standardized, \"standardized\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE for Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latents_tfce(train_lat, test_lat, pred_lat, imagery_pred_lat, title, train_subset=1000):\n",
    "    train_latents_subset = train_latents[np.random.choice(range(len(train_lat)), size=train_subset, replace=False)]\n",
    "    \n",
    "    tsne = TSNE(n_components=2, learning_rate='auto', verbose=1, n_jobs=10, n_iter=1000)\n",
    "    X_embedded = tsne.fit_transform(np.concatenate((train_latents_subset, test_lat, pred_lat, imagery_pred_lat)))\n",
    "    \n",
    "    print(X_embedded.shape)\n",
    "    assert X_embedded.shape[1] == 2\n",
    "    hue = ['train'] * len(train_latents_subset) + ['test'] * len(test_lat) + ['predictions'] * len(pred_lat) + ['imagery_predictions'] * len(imagery_pred_lat)\n",
    "    # alphas = [0.3] * len(train_latents_subset) + [1] * len(test_lat) + [1] * len(preds)\n",
    "    \n",
    "    plt.figure(figsize=(20, 12))\n",
    "    sns.scatterplot(\n",
    "        x = X_embedded[:, 0], y = X_embedded[:, 1],\n",
    "        hue = hue,\n",
    "        alpha = 0.8\n",
    "    )\n",
    "    plt.title(title)\n",
    "    \n",
    "plot_latents_tfce(train_latents, results['latents'], results['predictions'], results['imagery_predictions'], title=\"not standardized\")\n",
    "pred_latents_standardized = StandardScaler().fit_transform(results['predictions'])   \n",
    "imagery_pred_latents_standardized = StandardScaler().fit_transform(results['imagery_predictions'])\n",
    "plot_latents_tfce(train_latents, results['latents'], pred_latents_standardized, imagery_pred_latents_standardized, \"standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors with predictions averaged over subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 5\n",
    "N_SAMPLES = 5\n",
    "\n",
    "\n",
    "def plot_nn_table(stim_ids, nneighbors, stim_type):\n",
    "    df = pd.DataFrame({'stimulus': stim_ids} | {f'nn_{i}': [n[i] for n in nneighbors] for i in range(len(nneighbors[0]))})\n",
    "        \n",
    "    def image_base64(img_id, length=150):\n",
    "        im = resize_img(coco_ds.get_img_by_coco_id(img_id), length=length)\n",
    "        with BytesIO() as buffer:\n",
    "            im.save(buffer, 'jpeg')\n",
    "            decoded = base64.b64encode(buffer.getvalue()).decode()\n",
    "            return decoded\n",
    "    \n",
    "    def stimulus_formatter(img_id, width=150, height=200):\n",
    "        if stim_type == IMAGE:\n",
    "            formatted = f'<div style=\"height:{height}px; width:{width}px; vertical-align:top\"><img src=\"data:image/jpeg;base64,{image_base64(img_id)}\"></div>'\n",
    "        elif stim_type == CAPTION:\n",
    "            formatted = f'<div style=\"height:{height}px; width:{width}px; vertical-align:top\">{coco_ds.captions[img_id]}</div>'\n",
    "        else:\n",
    "            formatted = f'<div style=\"height:{height}px; width:{width}px; vertical-align:top; text-align:left\"><img src=\"data:image/jpeg;base64,{image_base64(img_id)}\">'\n",
    "            formatted += f'<br>{coco_ds.captions[img_id]}</div>'\n",
    "        return formatted\n",
    "            \n",
    "    def image_and_cap_formatter(img_id, width=150, height=200):\n",
    "        img = image_base64(img_id)\n",
    "        formatted = f'<div style=\"height:{height}px; width:{width}px; vertical-align:top; text-align:left\"><img src=\"data:image/jpeg;base64,{img}\">'\n",
    "        cap = coco_ds.captions[img_id]\n",
    "        formatted += f'<br>{cap}</div>'\n",
    "        return formatted\n",
    "            \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    custom_formatters = {'stimulus': stimulus_formatter} | {f'nn_{i}': image_and_cap_formatter for i in range(len(nneighbors[0]))}\n",
    "\n",
    "    display(HTML(df.to_html(formatters=custom_formatters, escape=False, index=False)))\n",
    "\n",
    "\n",
    "def analysis_n_neighbors(test_preds, test_stim_ids, candidate_latents, candidate_latent_ids, stim_type, n_samples=N_SAMPLES, n_neighbors=N_NEIGHBORS):\n",
    "    dist_mat = get_distance_matrix(test_preds, candidate_latents)\n",
    "\n",
    "    acc = dist_mat_to_pairwise_acc(dist_mat, test_stim_ids)\n",
    "    print(f'pairwise acc: {acc:.2f}')\n",
    "    rank = dist_mat_to_rankings(dist_mat, test_stim_ids, candidate_latent_ids)\n",
    "    print(f'mean rank: {rank:.2f} / {dist_mat.shape[1]} ({rank/dist_mat.shape[1]:.2f})')\n",
    "\n",
    "\n",
    "    np.random.seed(7)\n",
    "    sampled_ids = np.random.choice(range(len(test_stim_ids)), n_samples, replace=False)\n",
    "    test_stim_ids = test_stim_ids[sampled_ids]\n",
    "    dist_mat = dist_mat[sampled_ids]\n",
    "\n",
    "    nneighbors = [candidate_latent_ids[np.argsort(nneighbors_row)][:n_neighbors] for nneighbors_row in dist_mat]\n",
    "\n",
    "    plot_nn_table(test_stim_ids, nneighbors, stim_type)\n",
    "\n",
    "    return acc, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 5\n",
    "N_SAMPLES = 10\n",
    "WHOLE_TRAIN_SET_AS_CANDIDATE_SET = True\n",
    "AVERAGE_IMG_AND_CAP_TEST_PREDS = False\n",
    "\n",
    "# MODEL = \"imagebind\"\n",
    "MODEL = \"dino-base\"\n",
    "\n",
    "# MODE = \"images\"\n",
    "# MODE = \"captions\"\n",
    "MODE = \"agnostic\"\n",
    "\n",
    "BETAS_SUFFIX = 'betas'\n",
    "# BETAS_SUFFIX = 'betas_backup'\n",
    "# BETAS_SUFFIX = 'betas_one_step_skip_one_back'\n",
    "\n",
    "BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "# RESTANDARDIZE_PREDS = True\n",
    "RESTANDARDIZE_PREDS = True if BETAS_SUFFIX == 'betas_backup' else False\n",
    "\n",
    "FEATS = 'default'\n",
    "TEST_FEATS = 'default'\n",
    "# FEATS = 'vision'\n",
    "# TEST_FEATS = 'vision'\n",
    "VISION_FEATS = 'default'\n",
    "LANG_FEATS = 'default'\n",
    "FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "all_preds = []\n",
    "all_preds_standardized = []\n",
    "all_train_stim_ids = []\n",
    "all_train_latents = []\n",
    "for subj in SUBJECTS:\n",
    "    stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths = load(BETAS_DIR, MODEL, subj, MODE, FEATS_CONFIG)\n",
    "  \n",
    "    pred_latents = results['predictions']\n",
    "   \n",
    "    if RESTANDARDIZE_PREDS:\n",
    "        print('standardizing predictions')\n",
    "        pred_latents = StandardScaler().fit_transform(pred_latents)   \n",
    "\n",
    "    all_preds.append(pred_latents)\n",
    "    all_train_stim_ids.append(stim_ids)\n",
    "    all_train_latents.append(train_latents)\n",
    "\n",
    "all_train_stim_ids = np.concatenate(all_train_stim_ids)\n",
    "all_train_latents = np.concatenate(all_train_latents)\n",
    "\n",
    "all_preds = np.mean(all_preds, axis=0)\n",
    "\n",
    "if AVERAGE_IMG_AND_CAP_TEST_PREDS:\n",
    "    test_stim_ids_avgd = np.mean([results['stimulus_ids'][results['stimulus_types'] == stim_type] for stim_type in [IMAGE, CAPTION]], axis=0) #TODO useless?\n",
    "    test_latents_avgd = np.mean([results['latents'][results['stimulus_types'] == stim_type] for stim_type in [IMAGE, CAPTION]], axis=0)\n",
    "    pred_latents_avgd = np.mean([all_preds[results['stimulus_types'] == stim_type] for stim_type in [IMAGE, CAPTION]], axis=0)\n",
    "    \n",
    "    if WHOLE_TRAIN_SET_AS_CANDIDATE_SET:\n",
    "        # account for case that sometimes both the image and the caption are part of the training set\n",
    "        unique_stim_ids, indices = np.unique(all_train_stim_ids, return_index=True)\n",
    "        unique_train_latents = all_train_latents[indices]\n",
    "        \n",
    "        candidate_latents = np.concatenate((test_latents_avgd, unique_train_latents))\n",
    "        candidate_latent_ids = np.concatenate((test_stim_ids_avgd, unique_stim_ids))\n",
    "    else:\n",
    "        candidate_latents = test_latents_avgd\n",
    "        candidate_latent_ids = test_stim_ids_avgd\n",
    "    \n",
    "    print('candidate set size: ', len(candidate_latent_ids))\n",
    "    \n",
    "    analysis_n_neighbors(pred_latents_avgd, test_stim_ids_avgd, candidate_latents, candidate_latent_ids, 'avg_caption_image', N_SAMPLES, N_NEIGHBORS)\n",
    "\n",
    "else:\n",
    "    for stim_type in [IMAGE]:#, CAPTION]:\n",
    "        print(f'decoding of {stim_type}s')\n",
    "        test_stim_ids_mod = results['stimulus_ids'][results['stimulus_types'] == stim_type]\n",
    "        test_latents_mod = results['latents'][results['stimulus_types'] == stim_type]\n",
    "    \n",
    "        pred_latents_mod = all_preds[results['stimulus_types'] == stim_type]\n",
    "            \n",
    "        if WHOLE_TRAIN_SET_AS_CANDIDATE_SET:\n",
    "            # account for case that sometimes both the image and the caption are part of the training set\n",
    "            unique_stim_ids, indices = np.unique(stim_ids, return_index=True)\n",
    "            unique_train_latents = train_latents[indices]\n",
    "            \n",
    "            candidate_latents = np.concatenate((test_latents_mod, unique_train_latents))\n",
    "            candidate_latent_ids = np.concatenate((test_stim_ids_mod, unique_stim_ids))\n",
    "        else:\n",
    "            candidate_latents = test_latents_mod\n",
    "            candidate_latent_ids = test_stim_ids_mod\n",
    "    \n",
    "        analysis_n_neighbors(pred_latents_mod, test_stim_ids_mod, candidate_latents, candidate_latent_ids, stim_type, N_SAMPLES, N_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbors of imagery trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 3\n",
    "N_SAMPLES = 3\n",
    "WHOLE_TRAIN_SET_AS_CANDIDATE_SET = False\n",
    "\n",
    "MODEL = \"imagebind\"\n",
    "\n",
    "MODE = \"train_image\"\n",
    "# MODE = \"train_caption\"\n",
    "# MODE = \"train\"\n",
    "\n",
    "# BETAS_SUFFIX = 'betas'\n",
    "# BETAS_SUFFIX = 'betas_backup'\n",
    "BETAS_SUFFIX = 'betas_one_step_skip_one_back'\n",
    "BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "RESTANDARDIZE_PREDS = True\n",
    "# RESTANDARDIZE_PREDS = True if BETAS_SUFFIX == 'betas_backup' else False\n",
    "\n",
    "FEATS = 'default'\n",
    "TEST_FEATS = 'default'\n",
    "VISION_FEATS = 'default'\n",
    "LANG_FEATS = 'default'\n",
    "FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "all_pairwise_accs = []\n",
    "all_mean_ranks = []\n",
    "for subj in SUBJECTS:\n",
    "    print(subj)\n",
    "    stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths = load(BETAS_DIR, MODEL, subj, MODE, FEATS_CONFIG)\n",
    "    \n",
    "    pred_latents_imagery = results['imagery_predictions']\n",
    "    if RESTANDARDIZE_PREDS:\n",
    "        print('standardizing imagery predictions')\n",
    "        # pred_latents = results['predictions']\n",
    "        # transform = StandardScaler().fit(pred_latents)\n",
    "        # pred_latents_imagery = transform.transform(pred_latents_imagery)\n",
    "        pred_latents_imagery = StandardScaler().fit_transform(pred_latents_imagery)\n",
    "\n",
    "    test_stim_ids_mod = results['stimulus_ids'][results['stimulus_types'] == IMAGE]\n",
    "    test_latents_mod = results['latents'][results['stimulus_types'] == IMAGE]\n",
    "        \n",
    "    if WHOLE_TRAIN_SET_AS_CANDIDATE_SET:\n",
    "        # account for case that sometimes both the image and the caption are part of the training set\n",
    "        unique_stim_ids, indices = np.unique(stim_ids, return_index=True)\n",
    "        unique_train_latents = train_latents[indices]\n",
    "        \n",
    "        candidate_latents = np.concatenate((results['imagery_latents'], test_latents_mod, unique_train_latents))\n",
    "        candidate_latent_ids = np.concatenate((results['imagery_stimulus_ids'], test_stim_ids_mod, unique_stim_ids))\n",
    "    else:\n",
    "        candidate_latents = results['imagery_latents']\n",
    "        candidate_latent_ids = results['imagery_stimulus_ids']\n",
    "\n",
    "    acc, rank = analysis_n_neighbors(pred_latents_imagery, results['imagery_stimulus_ids'], candidate_latents, candidate_latent_ids, CAPTION, N_SAMPLES, N_NEIGHBORS)\n",
    "    all_pairwise_accs.append(acc)\n",
    "    all_mean_ranks.append(rank)\n",
    "\n",
    "print(f'Mean pairwise acc: {np.mean(all_pairwise_accs):.2f}')\n",
    "print(f'Mean rank: {np.mean(all_mean_ranks):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "64c2261fd1335a391d209058834a77a3cc43bbc1dadc63860e2129a303b1f182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
