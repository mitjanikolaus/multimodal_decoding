{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from utils import STIM_INFO_PATH, COCO_IMAGES_DIR, SUBJECTS, FMRI_DATA_DIR, RESULTS_DIR\n",
    "from eval import get_distance_matrix\n",
    "from data import get_fmri_data_paths, get_latent_features, LatentFeatsConfig, standardize_latents, IMAGE, CAPTION, SPLIT_TRAIN, SPLIT_TEST, SPLIT_IMAGERY, get_fmri_data, get_stim_info, IMAGERY\n",
    "from analyses.decoding.ridge_regression_decoding import get_run_str, RIDGE_DECODER_OUT_DIR, RESULTS_FILE\n",
    "from feature_extraction.feat_extraction_utils import CoCoDataset\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import trange\n",
    "import nibabel\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from pdf2image import convert_from_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_ds = CoCoDataset(COCO_IMAGES_DIR, STIM_INFO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img(image, length=100):\n",
    "    if image.size[0] < image.size[1]:\n",
    "        resized_image = image.resize((length, int(image.size[1] * (length / image.size[0]))))\n",
    "        required_loss = (resized_image.size[1] - length)\n",
    "        resized_image = resized_image.crop(box=(0, required_loss / 2, length, resized_image.size[1] - required_loss / 2))\n",
    "    else:\n",
    "        resized_image = image.resize((int(image.size[0] * (length / image.size[1])), length))\n",
    "        required_loss = resized_image.size[0] - length\n",
    "        resized_image = resized_image.crop(box=(required_loss / 2, 0, resized_image.size[0] - required_loss / 2, length))\n",
    "    return resized_image\n",
    "\n",
    "def display_stimuli(coco_ids, imgs=True, caps=True):\n",
    "    if caps:\n",
    "        for coco_id in coco_ids:\n",
    "            print(coco_ds.captions[coco_id], end=\"\\n\")\n",
    "\n",
    "    if imgs:\n",
    "        imgs = [np.array(resize_img(coco_ds.get_img_by_coco_id(img_id))) for img_id in coco_ids]        \n",
    "        img = Image.fromarray(np.hstack(imgs))\n",
    "        display(img)\n",
    "\n",
    "def get_distance_matrix(predictions, originals, metric='cosine'):\n",
    "    dist = cdist(predictions, originals, metric=metric)\n",
    "    return dist\n",
    "    \n",
    "def dist_mat_to_pairwise_acc(dist_mat, stim_ids, print_details=False):\n",
    "    diag = dist_mat.diagonal().reshape(-1, 1)\n",
    "    comp_mat = diag < dist_mat\n",
    "    corrects = comp_mat.sum()\n",
    "    if print_details:\n",
    "        for i, stim_id in enumerate(stim_ids):\n",
    "            print(stim_id, end=': ')\n",
    "            print(f'{comp_mat[i].sum() / (len(comp_mat[i]) - 1):.2f}')\n",
    "    # subtract the number of elements of the diagonal as these values are always \"False\" (not smaller than themselves)\n",
    "    score = corrects / (dist_mat.size - diag.size)\n",
    "    return score\n",
    "\n",
    "def dist_mat_to_rankings(dist_mat, stim_ids, candidate_set_latent_ids):\n",
    "    all_ranks = []\n",
    "    for test_stimulus_id, nneighbors_row in zip(stim_ids, dist_mat):\n",
    "        nneighbors_ids = np.array(candidate_set_latent_ids)[np.argsort(nneighbors_row)]\n",
    "        rank = np.argwhere(nneighbors_ids == test_stimulus_id)[0][0] + 1\n",
    "\n",
    "        all_ranks.append(rank)\n",
    "            \n",
    "    return np.mean(all_ranks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors of test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_results(betas_dir, subject, mode, feats_config, surface, mask=None):    \n",
    "    # train_paths, stim_ids, stim_types = get_fmri_data_paths(betas_dir, subject, SPLIT_TRAIN, mode)    \n",
    "    # train_latents = get_latent_features(feats_config, stim_ids, stim_types)\n",
    "    # train_paths = np.array(train_paths)\n",
    "    \n",
    "    # test_paths, test_stim_ids, test_stim_types = get_fmri_data_paths(betas_dir, subject, SPLIT_TEST)\n",
    "    # test_latents = get_latent_features(feats_config, test_stim_ids, test_stim_types, test_mode=True)\n",
    "    # test_paths = np.array(test_paths)\n",
    "    \n",
    "    # train_latents, test_latents = standardize_latents(train_latents, test_latents)\n",
    "    \n",
    "    run_str = get_run_str(betas_dir, feats_config, surface=surface, mask=mask)\n",
    "    results_file_path = os.path.join(\n",
    "        RIDGE_DECODER_OUT_DIR, mode, subject, run_str, RESULTS_FILE\n",
    "    )\n",
    "    print(f'loading decoder results from: \\n', results_file_path)\n",
    "    results = pickle.load(open(results_file_path, 'rb'))\n",
    "    \n",
    "    return results    \n",
    "    # return stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths\n",
    "\n",
    "def load_betas(train_paths, test_paths):\n",
    "    train_fmri_betas = []\n",
    "    for idx in trange(len(train_paths), desc=\"loading fmri data\"):\n",
    "        sample = nibabel.load(train_paths[idx]).get_fdata()\n",
    "        sample = sample[gray_matter_mask].astype('float32').reshape(-1)\n",
    "        train_fmri_betas.append(sample)\n",
    "    \n",
    "    train_fmri_betas = np.array(train_fmri_betas)\n",
    "\n",
    "    test_fmri_betas = []\n",
    "    for idx in trange(len(test_paths), desc=\"loading fmri data\"):\n",
    "        sample = nibabel.load(test_paths[idx]).get_fdata()\n",
    "        sample = sample[gray_matter_mask].astype('float32').reshape(-1)\n",
    "        test_fmri_betas.append(sample)\n",
    "    \n",
    "    test_fmri_betas = np.array(test_fmri_betas)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_fmri_betas)\n",
    "    train_fmri_betas_standardized = scaler.transform(train_fmri_betas)\n",
    "    test_fmri_betas_standardized = scaler.transform(test_fmri_betas)\n",
    "    \n",
    "    return train_fmri_betas, test_fmri_betas, train_fmri_betas_standardized, test_fmri_betas_standardized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 5\n",
    "N_SAMPLES = 5\n",
    "FONTSIZE = 13\n",
    "\n",
    "\n",
    "def plot_nn_table(stim_ids, nneighbors, subject, stim_type, out_file_name=None, img_length=150, hspace=0.2):\n",
    "    stimulus_key = 'Imagery sketch and initial\\ninstruction' if stim_type == IMAGERY else 'Stimulus'\n",
    "    figsize=(16, 11) if stim_type == IMAGERY else (16, 15)\n",
    "    \n",
    "    df = pd.DataFrame({stimulus_key: stim_ids} | {f'rank {i}': [n[i] for n in nneighbors] for i in range(len(nneighbors[0]))})\n",
    "\n",
    "    n_columns = len(nneighbors[0])+1#len(nneighbors[0])+2 if stim_type == IMAGERY else len(nneighbors[0])+1\n",
    "    fig, axes = plt.subplots(len(stim_ids),n_columns, figsize=figsize) #, layout=\"constrained\"\n",
    "\n",
    "    if stim_type == IMAGERY:\n",
    "        fig.subplots_adjust(wspace=0.05, hspace=hspace, top=0.97, bottom=0.06, left=0.01, right=0.99)   \n",
    "    else:\n",
    "        fig.subplots_adjust(wspace=0.05, hspace=hspace, top=0.98, bottom=0.03, left=0.01, right=0.99)  \n",
    "       \n",
    "\n",
    "    for idx, (stim_id, neighbors) in enumerate(zip(stim_ids, nneighbors)):\n",
    "        caption = coco_ds.captions[stim_id].lower()\n",
    "        img = resize_img(coco_ds.get_img_by_coco_id(stim_id), length=img_length)\n",
    "\n",
    "        if stim_type == IMAGE:\n",
    "            axes[idx][0].imshow(img)\n",
    "        elif stim_type == CAPTION:\n",
    "            img = Image.fromarray(np.full((img_length, img_length, 3), 255, dtype=np.uint8), \"RGB\")\n",
    "            axes[idx][0].imshow(img)\n",
    "            txt = axes[idx][0].text(0, img_length/2, caption, ha='left', wrap=True, fontsize=FONTSIZE,# verticalalignment='top', \n",
    "                                   bbox=dict(boxstyle='square,pad=0', facecolor='none', edgecolor='none'))\n",
    "            txt._get_wrap_line_width = lambda : img_length*4\n",
    "        elif stim_type == IMAGERY:\n",
    "            drawing_path = os.path.join(FMRI_RAW_BIDS_DATA_DIR, \"stimuli\", \"imagery_drawings\", f\"{subject}_imagery_{idx+1}.pdf\")\n",
    "            img_drawing = convert_from_path(drawing_path)[0]\n",
    "            img_drawing = resize_img(img_drawing, length=img_length)\n",
    "            \n",
    "            axes[idx][0].imshow(img_drawing)\n",
    "            txt = axes[idx][0].text(0, 155, caption, ha='left', wrap=True, fontsize=FONTSIZE, verticalalignment='top',\n",
    "                       bbox=dict(boxstyle='square,pad=0', facecolor='none', edgecolor='none'))\n",
    "            txt._get_wrap_line_width = lambda : img_length*4\n",
    "            # axes[idx][1].axis('off')\n",
    "            \n",
    "        axes[idx][0].axis('off')\n",
    "        \n",
    "        if idx == 0:\n",
    "            axes[idx][0].set_title(f'{stimulus_key}', fontweight=\"bold\")\n",
    "    \n",
    "\n",
    "        for n_id, neighbor_id in enumerate(neighbors):\n",
    "            caption = coco_ds.captions[neighbor_id].lower()\n",
    "            img = resize_img(coco_ds.get_img_by_coco_id(neighbor_id), length=img_length)\n",
    "            axes[idx][n_id+1].imshow(img)\n",
    "            axes[idx][n_id+1].axis('off')\n",
    "            if idx == 0:\n",
    "                axes[idx][n_id+1].set_title(f'Rank {n_id}', fontweight=\"bold\")\n",
    "\n",
    "            txt = axes[idx][n_id+1].text(0, 155, caption, ha='left', wrap=True, fontsize=12, verticalalignment='top',\n",
    "                                   bbox=dict(boxstyle='square,pad=0', facecolor='none', edgecolor='none'))\n",
    "            if stim_type == IMAGERY:\n",
    "                txt._get_wrap_line_width = lambda : img_length*4\n",
    "            else:\n",
    "                txt._get_wrap_line_width = lambda : img_length*4\n",
    "\n",
    " \n",
    "    if out_file_name is not None:\n",
    "        out_path = os.path.join(RESULTS_DIR, \"analysis_ranking\", out_file_name)\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        plt.savefig(out_path, dpi=250)\n",
    "\n",
    "\n",
    "def analysis_ranking(test_preds, test_stim_ids, candidate_latents, candidate_latent_ids, subject, stim_type, n_samples=N_SAMPLES, num_neighbors=N_NEIGHBORS, out_file_name=None, hspace=0.2):\n",
    "    dist_mat = get_distance_matrix(test_preds, candidate_latents)\n",
    "  \n",
    "    acc = dist_mat_to_pairwise_acc(dist_mat, test_stim_ids)\n",
    "    print(f'pairwise acc: {acc:.3f}')\n",
    "\n",
    "    if stim_type != IMAGERY:\n",
    "        np.random.seed(5)\n",
    "        sampled_ids = np.random.choice(range(len(test_stim_ids)), n_samples, replace=False)\n",
    "        test_stim_ids = np.array(test_stim_ids)[sampled_ids]\n",
    "        dist_mat = dist_mat[sampled_ids]\n",
    "\n",
    "    nneighbors = [np.array(candidate_latent_ids)[np.argsort(nneighbors_row)][:num_neighbors] for nneighbors_row in dist_mat]\n",
    "\n",
    "    plot_nn_table(test_stim_ids, nneighbors, subject, stim_type, out_file_name, hspace=hspace)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors with predictions averaged over subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 5\n",
    "N_SAMPLES = 5\n",
    "\n",
    "WHOLE_TRAIN_SET_AS_CANDIDATE_SET = True\n",
    "AVERAGE_IMG_AND_CAP_TEST_PREDS = False\n",
    "\n",
    "MODEL = \"imagebind\"\n",
    "\n",
    "SURFACE = True\n",
    "\n",
    "TRAINING_MODE = \"agnostic\"\n",
    "# TRAINING_MODE = \"images\"\n",
    "# TRAINING_MODE = \"captions\"\n",
    "\n",
    "BETAS_SUFFIX = 'betas'\n",
    "BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "RESTANDARDIZE_PREDS = True\n",
    "\n",
    "FEATS = 'default'\n",
    "TEST_FEATS = 'default'\n",
    "VISION_FEATS = 'default'\n",
    "LANG_FEATS = 'default'\n",
    "FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "all_preds = []\n",
    "all_preds_standardized = []\n",
    "all_train_stim_ids = []\n",
    "all_train_latents = []\n",
    "for subj in SUBJECTS:\n",
    "    stim_ids, _ = get_stim_info(subj, SPLIT_TRAIN)\n",
    "    \n",
    "    train_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_TRAIN)\n",
    "    test_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_TEST)\n",
    "    imagery_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_IMAGERY)\n",
    "    \n",
    "    train_latents, test_latents, imagery_latents = standardize_latents(\n",
    "        train_latents, test_latents, imagery_latents\n",
    "    )\n",
    "\n",
    "    results = load_results(BETAS_DIR, subj, TRAINING_MODE, FEATS_CONFIG, surface=SURFACE)  \n",
    "    pred_latents = results['predictions']\n",
    "   \n",
    "    if RESTANDARDIZE_PREDS:\n",
    "        print('standardizing predictions')\n",
    "        pred_latents = StandardScaler().fit_transform(pred_latents)   \n",
    "\n",
    "    all_preds.append(pred_latents)\n",
    "    all_train_stim_ids.append(stim_ids)\n",
    "    all_train_latents.append(train_latents)\n",
    "\n",
    "all_train_stim_ids = np.concatenate(all_train_stim_ids)\n",
    "all_train_latents = np.concatenate(all_train_latents)\n",
    "\n",
    "all_preds = np.mean(all_preds, axis=0)\n",
    "\n",
    "if AVERAGE_IMG_AND_CAP_TEST_PREDS:\n",
    "    test_stim_ids_avgd = results['stimulus_ids'][results['stimulus_types'] == IMAGE]\n",
    "    test_latents_avgd = np.mean([results['latents'][results['stimulus_types'] == stim_type] for stim_type in [IMAGE, CAPTION]], axis=0)\n",
    "    pred_latents_avgd = np.mean([all_preds[results['stimulus_types'] == stim_type] for stim_type in [IMAGE, CAPTION]], axis=0)\n",
    "    \n",
    "    if WHOLE_TRAIN_SET_AS_CANDIDATE_SET:\n",
    "        # account for case that sometimes both the image and the caption are part of the training set\n",
    "        unique_stim_ids, indices = np.unique(all_train_stim_ids, return_index=True)\n",
    "        unique_train_latents = all_train_latents[indices]\n",
    "        \n",
    "        candidate_latents = np.concatenate((test_latents_avgd, unique_train_latents))\n",
    "        candidate_latent_ids = np.concatenate((test_stim_ids_avgd, unique_stim_ids))\n",
    "    else:\n",
    "        candidate_latents = test_latents_avgd\n",
    "        candidate_latent_ids = test_stim_ids_avgd\n",
    "    \n",
    "    print('candidate set size: ', len(candidate_latent_ids))\n",
    "    \n",
    "    analysis_ranking(pred_latents_avgd, test_stim_ids_avgd, candidate_latents, candidate_latent_ids, 'avg', 'avg_caption_image', N_SAMPLES, N_NEIGHBORS, out_file_name=f\"avg_caption_image.svg\")\n",
    "\n",
    "else:\n",
    "    for stim_type in [IMAGE, CAPTION]:\n",
    "        print(f'decoding of {stim_type}s')\n",
    "        test_stim_ids_mod = results['stimulus_ids'][results['stimulus_types'] == stim_type]\n",
    "        test_latents_mod = results['latents'][results['stimulus_types'] == stim_type]\n",
    "    \n",
    "        pred_latents_mod = all_preds[results['stimulus_types'] == stim_type]\n",
    "            \n",
    "        if WHOLE_TRAIN_SET_AS_CANDIDATE_SET:\n",
    "            # account for case that sometimes both the image and the caption are part of the training set\n",
    "            unique_stim_ids, indices = np.unique(all_train_stim_ids, return_index=True)\n",
    "            unique_train_latents = all_train_latents[indices]\n",
    "            \n",
    "            candidate_latents = np.concatenate((test_latents_mod, unique_train_latents))\n",
    "            candidate_latent_ids = np.concatenate((test_stim_ids_mod, unique_stim_ids))\n",
    "        else:\n",
    "            candidate_latents = test_latents_mod\n",
    "            candidate_latent_ids = test_stim_ids_mod\n",
    "    \n",
    "        analysis_ranking(pred_latents_mod, test_stim_ids_mod, candidate_latents, candidate_latent_ids, 'avg', stim_type, N_SAMPLES, N_NEIGHBORS, out_file_name=f\"{stim_type}_decoding_with_{TRAINING_MODE}_decoder.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest neighbors of imagery trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NEIGHBORS = 5\n",
    "N_SAMPLES = 3\n",
    "\n",
    "WHOLE_TRAIN_AND_TEST_SET_AS_CANDIDATE_SET = True\n",
    "SURFACE = True\n",
    "\n",
    "MODEL = \"imagebind\"\n",
    "\n",
    "# TRAINING_MODE = \"images\"\n",
    "# TRAINING_MODE = \"captions\"\n",
    "TRAINING_MODE = \"agnostic\"\n",
    "\n",
    "MASK = None\n",
    "\n",
    "BETAS_SUFFIX = 'betas'\n",
    "\n",
    "BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "RESTANDARDIZE_PREDS = True\n",
    "\n",
    "FEATS = 'default'\n",
    "TEST_FEATS = 'default'\n",
    "VISION_FEATS = 'default'\n",
    "LANG_FEATS = 'default'\n",
    "FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "all_pairwise_accs = []\n",
    "for subj in SUBJECTS:\n",
    "    print(subj)\n",
    "\n",
    "    stim_ids, _ = get_stim_info(subj, SPLIT_TRAIN)\n",
    "    \n",
    "    train_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_TRAIN)\n",
    "    test_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_TEST)\n",
    "    imagery_latents = get_latent_features(FEATS_CONFIG, subj, SPLIT_IMAGERY)\n",
    "    \n",
    "    train_latents, test_latents, imagery_latents = standardize_latents(\n",
    "        train_latents, test_latents, imagery_latents\n",
    "    )\n",
    "\n",
    "    results = load_results(BETAS_DIR, subj, TRAINING_MODE, FEATS_CONFIG, surface=SURFACE, mask=MASK)\n",
    "        \n",
    "    pred_latents_imagery = results['imagery_predictions']\n",
    "    if RESTANDARDIZE_PREDS:\n",
    "        print('standardizing imagery predictions')\n",
    "        # pred_latents = results['predictions']\n",
    "        # transform = StandardScaler().fit(pred_latents)\n",
    "        # pred_latents_imagery = transform.transform(pred_latents_imagery)\n",
    "        pred_latents_imagery = StandardScaler().fit_transform(pred_latents_imagery)\n",
    "\n",
    "    test_stim_ids_mod = results['stimulus_ids'][results['stimulus_types'] == IMAGE]\n",
    "    test_latents_mod = results['latents'][results['stimulus_types'] == IMAGE]\n",
    "\n",
    "    if WHOLE_TRAIN_AND_TEST_SET_AS_CANDIDATE_SET:\n",
    "        # # account for case that sometimes both the image and the caption are part of the training set\n",
    "        # unique_stim_ids, indices = np.unique(stim_ids, return_index=True)\n",
    "        # unique_train_latents = train_latents[indices]\n",
    "        unique_stim_ids, indices = np.unique(all_train_stim_ids, return_index=True)\n",
    "        unique_train_latents = all_train_latents[indices]\n",
    "        print('candidate set size: ', len(unique_stim_ids))\n",
    "        \n",
    "        candidate_latents = np.concatenate((results['imagery_latents'], test_latents_mod, unique_train_latents))\n",
    "        candidate_latent_ids = np.concatenate((results['imagery_stimulus_ids'], test_stim_ids_mod, unique_stim_ids))\n",
    "    else:\n",
    "        candidate_latents = results['imagery_latents']\n",
    "        candidate_latent_ids = results['imagery_stimulus_ids']\n",
    "\n",
    "    acc = analysis_ranking(pred_latents_imagery, results['imagery_stimulus_ids'], candidate_latents, candidate_latent_ids, subj, IMAGERY, N_SAMPLES, N_NEIGHBORS, out_file_name=f\"{IMAGERY}_{TRAINING_MODE}_decoder_{subj}.png\", hspace=0.2)\n",
    "    all_pairwise_accs.append(acc)\n",
    "\n",
    "print(f'Mean pairwise acc: {np.mean(all_pairwise_accs):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE for Latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fmri_betas_full, train_stim_ids, train_stim_types = get_fmri_data(\n",
    "#     BETAS_DIR,\n",
    "#     SUBJECT,\n",
    "#     SPLIT_TRAIN,\n",
    "#     TRAINING_MODE,\n",
    "#     surface=SURFACE,\n",
    "# )\n",
    "# N_TRAIN_BETAS = 1000\n",
    "# train_paths = train_paths[np.random.choice(range(len(train_paths)), size=N_TRAIN_BETAS, replace=False)]\n",
    "\n",
    "# train_fmri_betas, test_fmri_betas, train_fmri_betas_standardized, test_fmri_betas_standardized = load_betas(train_paths, test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_betas(train_betas, test_betas, title, binwidth=3):\n",
    "#     X = np.concatenate((train_betas.flatten(), test_betas.flatten()))\n",
    "#     hue = ['train'] * train_betas.size + ['test'] * test_betas.size\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     sns.histplot(x=X, hue=hue, binwidth=binwidth)\n",
    "#     plt.title(title)\n",
    "\n",
    "# print(np.nanmean(train_fmri_betas.mean(axis=0)))\n",
    "# print(np.nanmean(test_fmri_betas.mean(axis=0)))\n",
    "# print(np.nanmean(train_fmri_betas_standardized.mean(axis=0)))\n",
    "# print(np.nanmean(test_fmri_betas_standardized.mean(axis=0)))\n",
    "\n",
    "# plot_betas(train_fmri_betas, test_fmri_betas, title='unstandardized')\n",
    "# plt.ylim(0, 10000000)\n",
    "# plt.xlim(-25, 25)\n",
    "\n",
    "# plot_betas(train_fmri_betas_standardized, test_fmri_betas, title='standardized', binwidth=0.3)\n",
    "# plt.ylim(0, 4000000)\n",
    "# plt.xlim(-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBJECT = 'sub-01'\n",
    "# MODEL = \"imagebind\"\n",
    "# SURFACE = True\n",
    "\n",
    "# # TRAINING_MODE = \"images\"\n",
    "# TRAINING_MODE = \"agnostic\"\n",
    "\n",
    "# BETAS_SUFFIX = 'betas'\n",
    "# BETAS_DIR = os.path.join(FMRI_DATA_DIR, BETAS_SUFFIX)\n",
    "\n",
    "# # feats = 'avg'\n",
    "# # test_feats = 'avg'\n",
    "# FEATS = 'default'\n",
    "# TEST_FEATS = 'default'\n",
    "# # feats = 'lang'\n",
    "# # test_feats = 'lang'\n",
    "# # vision_feats = 'vision_features_cls'\n",
    "# VISION_FEATS = 'default'\n",
    "# # vision_feats = 'n_a'\n",
    "\n",
    "# LANG_FEATS = 'default'\n",
    "# # lang_feats = 'lang_features_cls'\n",
    "# # lang_feats = 'lang_features_mean'\n",
    "\n",
    "# FEATS_CONFIG = LatentFeatsConfig(MODEL, FEATS, TEST_FEATS, VISION_FEATS, LANG_FEATS)\n",
    "\n",
    "\n",
    "# test_fmri_betas, test_stim_ids, test_stim_types = get_fmri_data(\n",
    "#     BETAS_DIR,\n",
    "#     SUBJECT,\n",
    "#     SPLIT_TEST,\n",
    "#     surface=SURFACE,\n",
    "# )\n",
    "# imagery_fmri_betas, imagery_stim_ids, imagery_stim_types = get_fmri_data(\n",
    "#     BETAS_DIR,\n",
    "#     SUBJECT,\n",
    "#     SPLIT_IMAGERY,\n",
    "#     surface=SURFACE,\n",
    "# )\n",
    "\n",
    "# train_latents = get_latent_features(FEATS_CONFIG, SUBJECT, SPLIT_TRAIN, mode=TRAINING_MODE)\n",
    "# test_latents = get_latent_features(FEATS_CONFIG, SUBJECT, SPLIT_TEST)\n",
    "# imagery_latents = get_latent_features(FEATS_CONFIG, SUBJECT, SPLIT_IMAGERY)\n",
    "\n",
    "# train_latents, test_latents, imagery_latents = standardize_latents(\n",
    "#     train_latents, test_latents, imagery_latents\n",
    "# )\n",
    "\n",
    "# results = load_results(BETAS_DIR, SUBJECT, TRAINING_MODE, FEATS_CONFIG, surface=SURFACE)\n",
    "\n",
    "# # stim_ids, stim_types, train_latents, gray_matter_mask, results, train_paths, test_paths = load(BETAS_DIR, MODEL, SUBJECT, MODE, FEATS_CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_latents_tsne(train_lat, test_lat, pred_lat, imagery_pred_lat, title, train_subset=1000):\n",
    "#     train_latents_subset = train_latents[np.random.choice(range(len(train_lat)), size=train_subset, replace=False)]\n",
    "    \n",
    "#     tsne = TSNE(n_components=2, learning_rate='auto', verbose=1, n_jobs=10, n_iter=1000)\n",
    "#     X_embedded = tsne.fit_transform(np.concatenate((train_latents_subset, test_lat, pred_lat, imagery_pred_lat)))\n",
    "    \n",
    "#     print(X_embedded.shape)\n",
    "#     assert X_embedded.shape[1] == 2\n",
    "#     hue = ['train'] * len(train_latents_subset) + ['test'] * len(test_lat) + ['predictions'] * len(pred_lat) + ['imagery_predictions'] * len(imagery_pred_lat)\n",
    "#     # alphas = [0.3] * len(train_latents_subset) + [1] * len(test_lat) + [1] * len(preds)\n",
    "    \n",
    "#     plt.figure(figsize=(20, 12))\n",
    "#     sns.scatterplot(\n",
    "#         x = X_embedded[:, 0], y = X_embedded[:, 1],\n",
    "#         hue = hue,\n",
    "#         alpha = 0.8\n",
    "#     )\n",
    "#     plt.title(title)\n",
    "\n",
    "# plot_latents_tsne(train_latents, results['latents'], results['predictions'], results['imagery_predictions'], title=\"not standardized\")\n",
    "\n",
    "# pred_latents_standardized = StandardScaler().fit_transform(results['predictions'])   \n",
    "# imagery_pred_latents_standardized = StandardScaler().fit_transform(results['imagery_predictions'])\n",
    "# plot_latents_tsne(train_latents, results['latents'], pred_latents_standardized, imagery_pred_latents_standardized, \"standardized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE for Betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_betas_tsne(train_betas, test_betas, title, train_subset=None):\n",
    "#     if train_subset is not None:\n",
    "#         train_betas_subset = train_betas[np.random.choice(range(len(train_betas)), size=train_subset, replace=False)]\n",
    "#     else:\n",
    "#         train_betas_subset = train_betas\n",
    "#     train_test = np.concatenate((train_betas_subset, test_betas))\n",
    "#     tsne = TSNE(n_components=2, learning_rate='auto', verbose=1, n_jobs=10, n_iter=1000)\n",
    "#     X_embedded = tsne.fit_transform(train_test)\n",
    "    \n",
    "#     print(X_embedded.shape)\n",
    "#     assert X_embedded.shape[1] == 2\n",
    "#     hue = ['train'] * len(train_betas_subset) + ['test'] * len(test_betas)\n",
    "#     # alpha = [1] * len(test_betas) + [0.3] * len(train_betas_subset)\n",
    "    \n",
    "#     plt.figure(figsize=(20, 12))\n",
    "#     sns.scatterplot(\n",
    "#         x = X_embedded[:, 0], y = X_embedded[:, 1],\n",
    "#         hue = hue,\n",
    "#         # alpha = alpha\n",
    "#     )\n",
    "#     plt.title(title)\n",
    "\n",
    "# plot_betas_tsne(train_fmri_betas, test_fmri_betas, title=\"not standardized\")\n",
    "# plot_betas_tsne(train_fmri_betas_standardized, test_fmri_betas_standardized, \"standardized\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "64c2261fd1335a391d209058834a77a3cc43bbc1dadc63860e2129a303b1f182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
