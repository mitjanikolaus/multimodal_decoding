{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-12T10:31:26.216288860Z",
     "start_time": "2023-12-12T10:31:26.209251348Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "from PIL import ImageColor\n",
    "import matplotlib.colors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import LATENT_FEATURES_DIR, RESULTS_DIR, SUBJECTS, FMRI_BETAS_SURFACE_DIR, STIM_INFO_PATH, COCO_IMAGES_DIR, METRIC_CROSS_DECODING, DECODER_ADDITIONAL_TEST_OUT_DIR, SUBJECTS_ADDITIONAL_TEST, FMRI_DATA_DIR\n",
    "from analyses.decoding.ridge_regression_decoding import NUM_CV_SPLITS, pairwise_accuracy\n",
    "from data import MODALITY_AGNOSTIC, MODALITY_SPECIFIC_IMAGES, MODALITY_SPECIFIC_CAPTIONS, TRAINING_MODES, CAPTION, IMAGE, SPLIT_TRAIN, TEST_SPLITS, SPLIT_IMAGERY, SPLIT_IMAGERY_WEAK, TEST_IMAGES, TEST_CAPTIONS, LatentFeatsConfig, get_stim_info, get_latents_for_splits, standardize_latents\n",
    "from eval import ACC_MODALITY_AGNOSTIC, ACC_CAPTIONS, ACC_IMAGES, ACC_CROSS_IMAGES_TO_CAPTIONS, ACC_CROSS_CAPTIONS_TO_IMAGES, ACC_IMAGERY, ACC_IMAGERY_WHOLE_TEST, get_distance_matrix\n",
    "from scipy.stats import ttest_rel\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from notebook_utils import load_predictions, get_data_default_feats\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results_data():\n",
    "    data = []\n",
    "\n",
    "    result_files = sorted(glob(f\"{DECODER_ADDITIONAL_TEST_OUT_DIR}/*/*/*/results.csv\"))\n",
    "    for result_file_path in tqdm(result_files):\n",
    "        results = pd.read_csv(result_file_path)\n",
    "        data.append(results)\n",
    "\n",
    "    data = pd.concat(data, ignore_index=True)\n",
    "    data[\"mask\"] = data[\"mask\"].fillna(\"whole_brain\")\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load_results_data()\n",
    "\n",
    "data = get_data_default_feats(data)\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "display(data)\n",
    "\n",
    "print(f\"Subjects: {data.subject.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[(data.subject == 'sub-01') & (data.model == 'imagebind') & (data.training_mode == 'agnostic') & (data['mask'] == 'whole_brain') & (data.standardized_predictions == 'True') & (data.training_splits == 'train')][['metric', 'value', 'latents']]) #\n",
    "# print(data[(data.subject == 'sub-01') & (data.model == 'imagebind') & (data.training_mode == 'agnostic') & (data['mask'] == 'whole_brain') & (data.training_splits == 'train') & (data.latents == 'all_candidate_latents')][['metric', 'value', 'latents', 'standardized_predictions']]) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = data.copy()\n",
    "\n",
    "# LATENT_MODE = 'all_candidate_latents'\n",
    "LATENT_MODE = 'limited_candidate_latents'\n",
    "MASK = 'whole_brain'\n",
    "TRAINING_SPLITS = 'train'\n",
    "MODEL = 'imagebind'\n",
    "\n",
    "filtered = filtered[filtered.model == MODEL]\n",
    "filtered = filtered[filtered.standardized_predictions == 'True']\n",
    "filtered = filtered[filtered.training_splits == TRAINING_SPLITS]\n",
    "filtered = filtered[filtered.latents == LATENT_MODE]\n",
    "filtered = filtered[filtered['mask'] == MASK]\n",
    "filtered = filtered[filtered.imagery_samples_weight.isna()]\n",
    "filtered = filtered[filtered.surface == True]\n",
    "\n",
    "# print(filtered.groupby(['metric', 'training_mode']).agg(num_subjects=('value', 'size')).reset_index())\n",
    "NUM_SUBJECTS = len(SUBJECTS_ADDITIONAL_TEST)\n",
    "expected_len = NUM_SUBJECTS * len(filtered.metric.unique()) * len(filtered.training_mode.unique())\n",
    "assert len(filtered) == expected_len, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = filtered.copy()\n",
    "\n",
    "ORDER = ['captions', 'images', 'agnostic']\n",
    "HUE_ORDER = ['test_image_attended', 'test_image_unattended']#, 'imagery', 'imagery_weak'] #'test_image', \n",
    "PALETTE = ['darkblue', 'cornflowerblue'] #blue\n",
    "\n",
    "to_plot = to_plot[to_plot.metric.isin(HUE_ORDER)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "# plt.title('image decoding', y=0.95, fontsize=20)\n",
    "# with sns.axes_style(\"white\"):\n",
    "ax = sns.barplot(data=to_plot, x=\"training_mode\", y=\"value\", hue=\"metric\", order=ORDER, hue_order=HUE_ORDER, palette=PALETTE)\n",
    "plt.ylim((0.5, 1))\n",
    "plt.ylabel('pairwise accuracy')\n",
    "\n",
    "\n",
    "ORDER = ['captions', 'images', 'agnostic']\n",
    "HUE_ORDER = ['test_image']\n",
    "to_plot_grouped = filtered.copy()\n",
    "to_plot_grouped = to_plot_grouped[to_plot_grouped.metric.isin(HUE_ORDER)]\n",
    "to_plot_grouped = to_plot_grouped.groupby(['training_mode']).agg(value=('value', 'mean')).reset_index()\n",
    "# display(to_plot)\n",
    "# with sns.axes_style(\"white\"):\n",
    "sns.scatterplot(data=to_plot_grouped, x=\"training_mode\", y=\"value\", marker=\"_\", color='black', s=500)\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f\"attention_modulation_images.png\"), bbox_inches='tight', pad_inches=0, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis: mod-agnostic decoders (and cross-decoding) should suffer more from missing attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_stats = to_plot[to_plot.training_mode.isin(['images', 'agnostic'])]\n",
    "# display(for_stats)\n",
    "# print(ttest_rel(for_stats[for_stats.metric == 'test_image_attended'].value, for_stats[for_stats.metric == 'test_image_unattended'].value))\n",
    "\n",
    "for_stats = for_stats[['model', 'subject', 'training_mode', 'value', 'metric']]\n",
    "\n",
    "mod = smf.mixedlm(\"value ~ metric * training_mode\", for_stats, groups=for_stats[\"subject\"]).fit()\n",
    "\n",
    "print(mod.summary())\n",
    "print('pvalues:\\n', mod.pvalues)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = filtered.copy()\n",
    "\n",
    "ORDER = ['captions', 'images', 'agnostic']\n",
    "HUE_ORDER = ['test_caption_attended', 'test_caption_unattended']#, 'imagery', 'imagery_weak'] #'test_caption', \n",
    "PALETTE = ['darkgreen', 'limegreen'] #'green', \n",
    "\n",
    "to_plot = to_plot[to_plot.metric.isin(HUE_ORDER)]\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "# plt.title('caption decoding', y=0.95, fontsize=20)\n",
    "ax = sns.barplot(data=to_plot, x=\"training_mode\", y=\"value\", hue=\"metric\", order=ORDER, hue_order=HUE_ORDER, palette=PALETTE)\n",
    "plt.ylabel('pairwise accuracy')\n",
    "plt.ylim((0.5, 1))\n",
    "\n",
    "ORDER = ['captions', 'images', 'agnostic']\n",
    "HUE_ORDER = ['test_caption']\n",
    "to_plot_grouped = filtered.copy()\n",
    "to_plot_grouped = to_plot_grouped[to_plot_grouped.metric.isin(HUE_ORDER)]\n",
    "# display(to_plot)\n",
    "\n",
    "to_plot_grouped = to_plot_grouped.groupby(['training_mode']).agg(value=('value', 'mean')).reset_index()\n",
    "\n",
    "sns.scatterplot(data=to_plot_grouped, x=\"training_mode\", y=\"value\", marker=\"_\", color='black', s=500)\n",
    "\n",
    "sns.despine()\n",
    "plt.savefig(os.path.join(RESULTS_DIR, f\"attention_modulation_captions.png\"), bbox_inches='tight', pad_inches=0, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_stats = to_plot[to_plot.training_mode.isin(['captions', 'agnostic'])]\n",
    "# print(ttest_rel(for_stats[for_stats.metric == 'test_caption_attended'].value, for_stats[for_stats.metric == 'test_caption_unattended'].value))\n",
    "\n",
    "for_stats = for_stats[['model', 'subject', 'training_mode', 'value', 'metric']]\n",
    "\n",
    "mod = smf.mixedlm(\"value ~ metric * training_mode\", for_stats, groups=for_stats[\"subject\"]).fit()\n",
    "\n",
    "print(\"=\" * 50 + \"\\nGLM\\n\" + \"=\" * 50)\n",
    "print(mod.summary())\n",
    "print('pvalues:\\n', mod.pvalues)\n",
    "print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  },
  "vscode": {
   "interpreter": {
    "hash": "64c2261fd1335a391d209058834a77a3cc43bbc1dadc63860e2129a303b1f182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
